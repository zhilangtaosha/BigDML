## 流处理

[TOC]

### 数据源接口

#### kafka

分布式消息发布和订阅系统

**kafka集群**

![kafka集群](http://www.aboutyun.com/data/attachment/forum/201409/28/143553z1pif7uok8ezr61u.png?_=3999538)

**topic/log**

![主题和日志](http://www.aboutyun.com/data/attachment/forum/201409/28/143553t3nhnsbri6s6nfh5.png?_=3999538)

在每个分区追加日志信息，日志信息用偏移量offset来唯一标记一条消息，offset被consumer所使用，并被保存在zookeeper中

> 消息被消费，消息仍然不会被立即删除，日志文件将会根据broker中的配置要求，保留一定的时间之后删除；

> 消息分区的机制来避免文件尺寸达到单击磁盘的上限，每个partition都会被当前server(kafka实例)保存

**分发**

> 待完成

#### flume

![flume使用](http://flume.apache.org/_images/DevGuide_image00.png)

分布式、可靠、高可用海量日志聚合系统，支持在系统中定制各类数据发送方，用于接收数据，同时flume提供对数据进行简单处理能力，并写到数据接收方，数据接收方可以是HDFS，其架构如下：

![flume逻辑架构](http://pic002.cnblogs.com/images/2012/384764/2012052509592437.jpg)

分层架构：

agent和collector均由两部分组成，source和sink,source是数据来源，sink是数据去向。

**agent**

agent的作用是将数据源的数据发送给collector,flume自身带的可用数据源；另外提供了sink来指定数据的去向，例如写到控制台，写到文本文件，写到hdfs，或者通过tcp将数据传递给其它节点。

**collector**

collector的作用是将多个agent的数据汇总后，加载到storage中。它的source和sink和agent类型。

**storage**

storage是存储心，可以是普通的文件，也可以是HDFS,HIVE,HBASE等，如果是HIVE等，其實現的只是簡單的數據收集，而數據的處理是在<!--哪裡進行的-->

**Master**

master是管理協調agent和collector的配置等心，是flume集群的控制器。

關鍵概念的理解：

- 信息流

![flume信息流](http://pic002.cnblogs.com/images/2012/384764/2012052510101772.jpg)

1. agent的數據流配置是從哪裡得到數據，把數據發送到那個collector
2. collector是接收agent發過來的數據，然後把數據發送到指定的機器上

```
flume框架隊hadoop和zookeeper的依賴只是在jar包上，并不需要flume啟動時候必須將hadoop和zookeeper也啟動。
```

環境部署

```
流程如下：
1. 在集群的每台機器上安裝flume
2. 選擇一個或多個節點當做mater
3. 修改靜態配置文件
4. 在至少一臺機器上啟動一個master,所有節點啟動flume node
5. 動態配置（配置信息是mater控制，控制哪些節點是agent，哪些節點是collector）
```



### 流处理框架

> 自建流处理框架还是采用已有的云平台日志处理框架，如百度云、阿里云等

#### storm

#### spark streaming

#### Samza



## 参考

### kafka部分

[Kafka集群搭建](http://www.cnblogs.com/luotianshuai/p/5206662.html)

### flume部分

[flume原理介绍和安装](http://www.cnblogs.com/oubo/archive/2012/05/25/2517751.html)